{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CaptainJimbo/MyPortfolio/blob/main/Solving_The_Three_Body_Problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table align=\"left\">\n",
        "  <td align=\"left\">\n",
        "  <a target=\"_blank\" href=\"https://dimitriskogias.wixsite.com/spacecowboy\" style=\"text-decoration: none; display: flex; align-items: center; color: white; background-color: purple; padding: 10px; border-radius: 5px;\">\n",
        "      <img src=\"https://static.wikia.nocookie.net/bravestarr/images/6/6d/Lucas_Conway.png/revision/latest?cb=20211111224054\" width=\"40px\" height=\"40px\" style=\"border-radius: 50%; margin-right: 10px;\" />\n",
        "      <span>Visit my Webpage</span>\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n"
      ],
      "metadata": {
        "id": "X0VQQJ0jfGbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table align=\"left\">\n",
        "  <td align=\"left\"><a target=\"_blank\" href=\"https://github.com/CaptainJimbo/MyPortfolio/blob/main/Solving_The_Three_Body_Problem.ipynb\" style=\"text-decoration: none; display: flex; align-items: center; color: black; background-color: lightgray; padding: 10px; border-radius: 5px;\">\n",
        "        <img src=\"https://i.ibb.co/xfJbPmL/github.png\"  width=\"40px\" height=\"40px\" style=\"border-radius: 50%; margin-right: 10px;\"   />View it on GitHub</a></td>\n",
        "</table>\n"
      ],
      "metadata": {
        "id": "yqm5SEetfX3b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rk50QdI0e_3S",
        "outputId": "48385155-e365-47ae-c143-e969ee203f73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-09 18:14:56--  https://dl.dropboxusercontent.com/s/p5u9w3v8nctjdut/Breen_NN_project2.h5\n",
            "Resolving dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:6019:15::a27d:40f\n",
            "Connecting to dl.dropboxusercontent.com (dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1870184 (1.8M) [text/plain]\n",
            "Saving to: ‘Breen_NN_project2.h5’\n",
            "\n",
            "Breen_NN_project2.h 100%[===================>]   1.78M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-07-09 18:14:57 (169 MB/s) - ‘Breen_NN_project2.h5’ saved [1870184/1870184]\n",
            "\n",
            "--2023-07-09 18:14:57--  https://dl.dropboxusercontent.com/s/mjcuk5t2i1nrpoc/data_project2.npz\n",
            "Resolving dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:6019:15::a27d:40f\n",
            "Connecting to dl.dropboxusercontent.com (dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 519093502 (495M) [application/octet-stream]\n",
            "Saving to: ‘data_project2.npz’\n",
            "\n",
            "data_project2.npz   100%[===================>] 495.05M   121MB/s    in 4.0s    \n",
            "\n",
            "2023-07-09 18:15:02 (125 MB/s) - ‘data_project2.npz’ saved [519093502/519093502]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# Datasets\n",
        "#!wget https://dl.dropboxusercontent.com/s/p5u9w3v8nctjdut/Breen_NN_project2.h5\n",
        "#!wget https://dl.dropboxusercontent.com/s/mjcuk5t2i1nrpoc/data_project2.npz\n",
        "\n",
        "!wget https://dl.dropboxusercontent.com/s/p5u9w3v8nctjdut/Breen_NN_project2.h5 -O Breen_NN_project2.h5\n",
        "!wget https://dl.dropboxusercontent.com/s/mjcuk5t2i1nrpoc/data_project2.npz -O data_project2.npz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmUNS2k8e_3V"
      },
      "outputs": [],
      "source": [
        "# functions\n",
        "\n",
        "def get_data(idx):\n",
        "    x = np. array([data[idx,:,0],data[idx,:,3],data[idx,:,4]]).T   #t,x2,y2 shape=(time steps,3)\n",
        "    y = np.array([data[idx,:,1],data[idx,:,2],data[idx,:,3],data[idx,:,4]]).T  #x1,y1,x2,y2 shape=(time steps,4)\n",
        "    return x,y\n",
        "\n",
        "def get_training_data(idx):\n",
        "    data = training_data\n",
        "    x = np. array([data[idx,:,0],data[idx,:,3],data[idx,:,4]]).T   #t,x2,y2 shape=(time steps,3)\n",
        "    y = np.array([data[idx,:,1],data[idx,:,2],data[idx,:,3],data[idx,:,4]]).T  #x1,y1,x2,y2 shape=(time steps,4)\n",
        "    return x,y\n",
        "\n",
        "def get_trajectories(pred):\n",
        "    # pred = x1,y1,x2,y2\n",
        "    p1 = np. array([pred[:,0],pred[:,1]]).T\n",
        "    p2 = np. array([pred[:,2],pred[:,3]]).T\n",
        "    p3 = -p1 -p2  # x1 + x2 + x3 = 0 , y1 + y2 + y3 = 0\n",
        "    return p1,p2,p3\n",
        "\n",
        "def plot_trajectories(p1, p2, p3, ax=None, style = '-', leg = None, **kwargs):\n",
        "    plt.plot(p1[:,0],p1[:,1],'r',linestyle = style , label = leg)\n",
        "    plt.plot(p1[0,0],p1[0,1],'ro')\n",
        "    plt.plot(p2[:,0],p2[:,1],'b',linestyle = style , label = leg)\n",
        "    plt.plot(p2[0,0],p2[0,1],'bo')\n",
        "    plt.plot(p3[:,0],p3[:,1],'g',linestyle = style , label = leg)\n",
        "    plt.plot(p3[0,0],p3[0,1],'go') # bullets for initial conditions\n",
        "\n",
        "    plt.legend(loc='best',fontsize='small');\n",
        "    #return NotImplementedError #wtfisthis\n",
        "\n",
        "def special_input(data,idx):\n",
        "    t = data[idx,:,0]\n",
        "    x2 = data[idx,:,3]*0 + data[idx,:,3][0] # 1000 element columns with the same initial position)\n",
        "    y2 = data[idx,:,4]*0 + data[idx,:,4][0] # from get data function[0]= t,x2,y2\n",
        "    return np.array([t,x2,y2]).T\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and unpack the compressed npy array\n",
        "load_data = np.load('data_project2.npz')\n",
        "data = load_data['arr_0']\n",
        "print(f'data.shape={data.shape}')\n",
        "print(f'this guy has {data.shape[0]} samples of {data.shape[2]} columns of (t,x1,y1,x2,y2,ux1,uy1,ux2,uy2) and each one has {data.shape[1]} elements')"
      ],
      "metadata": {
        "id": "IiT9dlTQwsuF",
        "outputId": "7ae06514-be8f-4e5f-a5db-bcdd3e186641",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.shape=(9000, 1000, 9)\n",
            "this guy has 9000 samples of 9 columns of (t,x1,y1,x2,y2,ux1,uy1,ux2,uy2) and each one has 1000 elements\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cxMagHaYe_3Z"
      },
      "outputs": [],
      "source": [
        "# lets load the pre trained model and predict some trajectories\n",
        "pre_trained_model = keras.models.load_model(\"Breen_NN_project2.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "scrolled": false,
        "id": "9ms7vjGNe_3a",
        "outputId": "6b40a4dd-fc09-48e5-ba3b-17cf3726cdcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training sample is the 90.0% of data and has size 8100.\n",
            " \n",
            "\n",
            " - The shape of the unshaped input training sample is (8100, 1000, 3), that is 8100 samples of 1000 snapshots of (t , x2(t)=x2_0 , y2(t)=y2_0). In order to have a valid training input we stack all samples by column and that changes the input training sample shape to (8100000, 3).\n",
            "\n",
            " - The shape of the unshaped output training sample is (8100, 1000, 4). In order to have a valid training output we stack all samples by column and that changes the output training sample shape to (8100000, 4).\n",
            "\n",
            "\n",
            "\n",
            "The validation sample is the 10.0% of data and has size  900.\n",
            " \n",
            "\n",
            " - The shape of the unshaped input validation sample is (900, 1000, 3), that is 900 samples of 1000 snapshots of (t , x2(t)=x2_0 , y2(t)=y2_0). In order to have a valid validation input we stack all samples by column and that changes the input validation sample shape to (900000, 3).\n",
            "\n",
            " - The shape of the unshaped output validation sample is (900, 1000, 4). In order to have a valid validation output we stack all samples by column and that changes the output validation sample shape to (900000, 4).\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#sample splitting\n",
        "train_percentage = 0.9\n",
        "training_data, validation_data = train_test_split(data ,train_size=train_percentage)\n",
        "size = len(training_data)\n",
        "input_data_unshaped = np.zeros(((size,1000,3)))# still (t,x2,y2)\n",
        "\n",
        "# this special_input  fucntion that changes x2,y2 snapshots to x2_0,y2_0 everywhere\n",
        "for idx in range(size):\n",
        "    input_data_unshaped [idx] = special_input(training_data,idx)\n",
        "\n",
        "# input data reshaping\n",
        "train_input_data = input_data_unshaped.reshape(-1,3)\n",
        "print(f'The training sample is the {train_percentage*100}% of data and has size {size}.\\n \\\n",
        "\\n\\n - The shape of the unshaped input training sample is {input_data_unshaped.shape}, that is {size} samples of \\\n",
        "1000 snapshots of (t , x2(t)=x2_0 , y2(t)=y2_0). In order to have a valid training input we stack all samples \\\n",
        "by column and that changes the input training sample shape to {train_input_data.shape}.')\n",
        "\n",
        "output_data_unshaped = training_data[:,:,:5][:,:,1:]\n",
        "train_output_data = output_data_unshaped.reshape(-1,4)\n",
        "print (f'\\n - The shape of the unshaped output training sample is {output_data_unshaped.shape}. In order to have a\\\n",
        " valid training output we stack all samples by column and that changes the output training sample \\\n",
        "shape to {train_output_data.shape}.')\n",
        "\n",
        "\n",
        "\n",
        "val_percentage = 0.1\n",
        "size = len(validation_data)\n",
        "input_data_unshaped = np.zeros(((size,1000,3)))# still (t,x2,y2)\n",
        "\n",
        "# this special_input  fucntion that changes x2,y2 snapshots to x2_0,y2_0 everywhere\n",
        "for idx in range(size):\n",
        "    input_data_unshaped [idx] = special_input(validation_data,idx)\n",
        "\n",
        "# input data reshaping\n",
        "val_input_data = input_data_unshaped.reshape(-1,3)\n",
        "print(f'\\n\\n\\nThe validation sample is the {val_percentage*100}% of data and has size  {size}.\\n \\\n",
        "\\n\\n - The shape of the unshaped input validation sample is {input_data_unshaped.shape}, that is {size} samples of \\\n",
        "1000 snapshots of (t , x2(t)=x2_0 , y2(t)=y2_0). In order to have a valid validation input we stack all samples \\\n",
        "by column and that changes the input validation sample shape to {val_input_data.shape}.')\n",
        "\n",
        "output_data_unshaped = validation_data[:,:,:5][:,:,1:]\n",
        "val_output_data = output_data_unshaped.reshape(-1,4)\n",
        "print (f'\\n - The shape of the unshaped output validation sample is {output_data_unshaped.shape}. In order to have a\\\n",
        " valid validation output we stack all samples by column and that changes the output validation sample \\\n",
        "shape to {val_output_data.shape}.')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "scrolled": true,
        "id": "NeZ-GuY1e_3c",
        "outputId": "5bb23794-4d19-4f7a-a378-5f66d16be735",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Recap: \n",
            "\n",
            " train_input_data.shape = (8100000, 3)\n",
            " train_output_data.shape = (8100000, 4) \n",
            " val_input_data.shape = (900000, 3)\n",
            " val_output_data.shape = (900000, 4) \n"
          ]
        }
      ],
      "source": [
        "print(f' Recap: \\n')\n",
        "print(f' train_input_data.shape = {train_input_data.shape}\\n train_output_data.shape = {train_output_data.shape} \\n \\\n",
        "val_input_data.shape = {val_input_data.shape}\\n val_output_data.shape = {val_output_data.shape} ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ofsdYnn2e_3d"
      },
      "outputs": [],
      "source": [
        "# creating the data_sets\n",
        "\n",
        "# my inputs/outputs have dimensions (8100000,3)/(8100000,4)\n",
        "training_dataset = tf.data.Dataset.from_tensor_slices((train_input_data,train_output_data))\n",
        "\n",
        "# my inputs/outputs have dimensions (900000,3)/(900000,4)\n",
        "validation_dataset =  tf.data.Dataset.from_tensor_slices((val_input_data,val_output_data))\n",
        "\n",
        "# batches of 5 samples (5*1000)\n",
        "training_dataset = training_dataset.batch(5000)\n",
        "validation_dataset = validation_dataset.batch(5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gxTpSpxYe_3e",
        "outputId": "fa70fd84-085a-418b-e914-3b1a0263804e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               512       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 149,636\n",
            "Trainable params: 149,636\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# my Neural Network\n",
        "myNN = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(3)),  #input\n",
        "    tf.keras.layers.Dense(128, activation='relu'), #1\n",
        "    tf.keras.layers.Dense(128, activation='relu'), #2\n",
        "    tf.keras.layers.Dense(128, activation='relu'), #3\n",
        "    tf.keras.layers.Dense(128, activation='relu'), #4\n",
        "    tf.keras.layers.Dense(128, activation='relu'), #5\n",
        "    tf.keras.layers.Dense(128, activation='relu'), #6\n",
        "    tf.keras.layers.Dense(128, activation='relu'), #7\n",
        "    tf.keras.layers.Dense(128, activation='relu'), #8\n",
        "    tf.keras.layers.Dense(128, activation='relu'), #9\n",
        "    tf.keras.layers.Dense(128, activation='relu'), #10\n",
        "    tf.keras.layers.Dense(4)                      #output\n",
        "])\n",
        "\n",
        "# summary\n",
        "myNN.summary()\n",
        "\n",
        "# compiler\n",
        "myNN.compile(optimizer=keras.optimizers.Adam(0.001, 0.5, 0.5)\n",
        "              ,loss=keras.losses.MeanAbsoluteError(),\n",
        "              metrics=['mse'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "scrolled": false,
        "id": "1PyJZ6xie_3g",
        "outputId": "c22b6618-4433-4fd0-e57b-af0ede0ed3fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-e25ff07499b0>:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  result = myNN.fit_generator(training_dataset, epochs=10, validation_data = validation_dataset) # epochs=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 583/1620 [=========>....................] - ETA: 1:33 - loss: 0.2645 - mse: 0.2187"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-e25ff07499b0>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# epochs=100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# This best runs for 100 epochs with loss ~ 0.07 and takes ~ 230 minutes, if you want to wait.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtotal_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2634\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m         )\n\u001b[0;32m-> 2636\u001b[0;31m         return self.fit(\n\u001b[0m\u001b[1;32m   2637\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#training of myNN\n",
        "\n",
        "start =  time.perf_counter()\n",
        "end = time.perf_counter()\n",
        "result = myNN.fit_generator(training_dataset, epochs=10, validation_data = validation_dataset) # epochs=100\n",
        "# This best runs for 100 epochs with loss ~ 0.07 and takes ~ 230 minutes, if you want to wait.\n",
        "total_time = end - start\n",
        "print(f'total time is {round(total_time/60)} minutes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "OZHfu5K7e_3h"
      },
      "outputs": [],
      "source": [
        "#result.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqMQq-HOe_3i"
      },
      "outputs": [],
      "source": [
        "# plotting mae vs epoch\n",
        "result.history['mse']\n",
        "plt.figure(figsize=(14,8))\n",
        "plt.title('mean absolute error vs epochs ,  time <= 3.9 time units' ,size=20)\n",
        "plt.plot(result.history['mse'],'r');\n",
        "plt.xlabel('epoch',size=15)\n",
        "plt.ylabel('mean absolute error',size=15);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tI284Cte_3k"
      },
      "outputs": [],
      "source": [
        "# Lets compare my NN with the pre trained model from the paper\n",
        "\n",
        "# i pick a random initial condition\n",
        "idxrand = np.random.randint(9000)\n",
        "\n",
        "# prediction for my NN nad plotting\n",
        "predictions = myNN.predict( special_input(data, idxrand))\n",
        "r1 , r2, r3 = get_trajectories(predictions)\n",
        "# i discarded the first points of x1,y1,x2,y2, the x1,y1(0) was not (1,0) the x1,y1(1) was fine about (1,0)\n",
        "plot_trajectories(r1[1:,:] , r2[1:,:] , r3[1:,:], ax=None , leg = 'my NN')\n",
        "k1 = r1\n",
        "# prediction for pre trained model and plotting\n",
        "predictions = pre_trained_model.predict( special_input(data, idxrand))\n",
        "r1 , r2 , r3 = get_trajectories(predictions)\n",
        "plot_trajectories(r1, r2, r3, ax=None, style='--',leg = 'pre trained')\n",
        "print(f'             myNN                       pretrained\\n\\n {np.hstack((k1,r1))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rY4Geq6Oe_3m"
      },
      "outputs": [],
      "source": [
        "predictions = pre_trained_model.predict( special_input(data, idxrand))\n",
        "r1 , r2 , r3 = get_trajectories(predictions)\n",
        "plot_trajectories(r1, r2, r3, ax=None, style ='--',leg = 'pre trained')\n",
        "k1 = r1\n",
        "r1 , r2 , r3 = get_trajectories(get_data(idxrand)[1])\n",
        "plot_trajectories(r1, r2, r3, ax=None, style ='-', leg = 'original')\n",
        "print(f'             predicted                       original\\n\\n {np.hstack((k1,r1))}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDAB31vge_3n"
      },
      "outputs": [],
      "source": [
        "#from datetime import datetime\n",
        "#now = datetime.now()\n",
        "#current_datetime = now.strftime(\"%D,%H-%M-%S\")\n",
        "#name = 'myNN_mk2('+current_datetime+').h5'\n",
        "\n",
        "# saving model\n",
        "tf.keras.models.save_model(myNN, 'myNN_10_128.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21oJGEK1e_3o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}